{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 ms, sys: 0 ns, total: 36 ms\n",
      "Wall time: 52.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please provide your own S3 bucket below. The name for your bucket must contain the prefix ‘deeplens’. In this example, the bucket is ‘deeplens-imageclassification’. Make Sure S3 bucket name is unique, e.g. deeplens-imageclassfication-name-date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket='deeplens-image-classification-varunrao'\n",
    "s3_key = 'imagenet_updated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "containers = {'us-west-2': '433757028032.dkr.ecr.us-west-2.amazonaws.com/image-classification:latest',\n",
    "              'us-east-1': '811284229777.dkr.ecr.us-east-1.amazonaws.com/image-classification:latest',\n",
    "              'us-east-2': '825641698319.dkr.ecr.us-east-2.amazonaws.com/image-classification:latest',\n",
    "              'eu-west-1': '685385470294.dkr.ecr.eu-west-1.amazonaws.com/image-classification:latest'}\n",
    "training_image = containers[boto3.Session().region_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import urllib.request\n",
    "import boto3\n",
    "\n",
    "# def download(url):\n",
    "#     filename = url.split(\"/\")[-1]\n",
    "#     if not os.path.exists(filename):\n",
    "#         urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "        \n",
    "# def upload_to_s3(channel, file):\n",
    "#     s3 = boto3.resource('s3')\n",
    "#     data = open(file, \"rb\")\n",
    "#     key = channel + '/' + file\n",
    "#     s3.Bucket(bucket).put_object(Key=key, Body=data)\n",
    "# # caltech-256\n",
    "# download('http://data.mxnet.io/data/caltech-256/caltech-256-60-train.rec')\n",
    "# upload_to_s3('train', 'caltech-256-60-train.rec')\n",
    "# download('http://data.mxnet.io/data/caltech-256/caltech-256-60-val.rec')\n",
    "# upload_to_s3('validation', 'caltech-256-60-val.rec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please make sure number set for epochs is same as checkpoint_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The algorithm supports multiple network depth (number of layers). They are 18, 34, 50, 101, 152 and 200\n",
    "# # For this training, we will use 18 layers\n",
    "# # This can be tuned\n",
    "# #num_layers = \"18\" \n",
    "# num_layers = \"152\" \n",
    "# # we need to specify the input image shape for the training data\n",
    "# image_shape = \"3,480,480\"\n",
    "# # RGB, Image size\n",
    "# #image_shape = \"3,224,224\"\n",
    "# # we also need to specify the number of training samples in the training set\n",
    "# # for caltech it is 15420\n",
    "# #num_training_samples = \"2527\"\n",
    "# num_training_samples = \"4712\"\n",
    "# # specify the number of output classes\n",
    "# num_classes = \"4\"\n",
    "# # batch size for training\n",
    "# #mini_batch_size =  \"50\"\n",
    "# mini_batch_size =  \"50\"\n",
    "# # number of epochs\n",
    "# #epochs = \"10\"\n",
    "# epochs = \"30\"\n",
    "# # learning rate\n",
    "# # Tune\n",
    "# learning_rate = \"1.25e-5\"\n",
    "# #learning_rate = \"0.5e-3\"\n",
    "# #optimizer\n",
    "# #optimizer ='Adam'\n",
    "# #checkpoint_frequency\n",
    "# checkpoint_frequency = \"10\"\n",
    "# #scheduler_step\n",
    "# lr_scheduler_step=\"30,90,180\"\n",
    "# #scheduler_factor\n",
    "# lr_scheduler_factor=\"0.1\"\n",
    "# #augmentation_type\n",
    "# augmentation_type=\"crop_color_transform\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The algorithm supports multiple network depth (number of layers). They are 18, 34, 50, 101, 152 and 200\n",
    "# For this training, we will use 18 layers\n",
    "num_layers = \"200\" \n",
    "# we need to specify the input image shape for the training data\n",
    "image_shape = \"3,224,224\"\n",
    "# we also need to specify the number of training samples in the training set\n",
    "# for caltech it is 15420\n",
    "num_training_samples = \"5085\"\n",
    "# specify the number of output classes\n",
    "num_classes = \"7\"\n",
    "# batch size for training\n",
    "mini_batch_size =  \"128\"\n",
    "# number of epochs\n",
    "epochs = \"150\"\n",
    "# learning rate\n",
    "learning_rate = \"0.1\"\n",
    "lr_scheduler_factor=\"0.1\"\n",
    "lr_scheduler_step=\"30,60,90\"\n",
    "#augmentation_type=\"crop_color_transform\"\n",
    "checkpoint_frequency = \"150\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please make job_name_prefix below unique so that its easy to remember in Deeplens projects.\n",
    "### InstanceType below is using ml.p3.2xlarge but if you dont have these instances in your account then you can use non GPU instaces such as ml.c5.xlarge. please check https://aws.amazon.com/sagemaker/pricing/instance-types for more different instance types available for Sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job name: trashnet-imageclassification-2018-11-27-18-58-35\n",
      "\n",
      "Input Data Location: {'S3DataType': 'S3Prefix', 'S3Uri': 's3://deeplens-image-classification-varunrao/imagenet_updated/train/', 'S3DataDistributionType': 'ShardedByS3Key'}\n",
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 3.78 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "# create unique job name \n",
    "job_name_prefix = 'trashnet-imageclassification'\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "job_name = job_name_prefix + timestamp\n",
    "training_params = \\\n",
    "{\n",
    "    # specify the training docker image\n",
    "    \"AlgorithmSpecification\": {\n",
    "        \"TrainingImage\": training_image,\n",
    "        \"TrainingInputMode\": \"File\"\n",
    "    },\n",
    "    \"RoleArn\": role,\n",
    "    \"OutputDataConfig\": {\n",
    "        \"S3OutputPath\": 's3://{}/{}/{}/output'.format(bucket, s3_key, job_name_prefix)\n",
    "    },\n",
    "    \"ResourceConfig\": {\n",
    "        \"InstanceCount\": 1,\n",
    "        \"InstanceType\": \"ml.p3.16xlarge\",\n",
    "        \"VolumeSizeInGB\": 100\n",
    "    },\n",
    "    \"TrainingJobName\": job_name,\n",
    "    \"HyperParameters\": {\n",
    "        \"image_shape\": image_shape,\n",
    "        \"num_layers\": str(num_layers),\n",
    "        \"num_training_samples\": str(num_training_samples),\n",
    "        \"num_classes\": str(num_classes),\n",
    "        \"mini_batch_size\": str(mini_batch_size),\n",
    "        \"epochs\": str(epochs),\n",
    "        \"learning_rate\": str(learning_rate),\n",
    "        \"lr_scheduler_step\": str(lr_scheduler_step),\n",
    "        \"lr_scheduler_factor\": str(lr_scheduler_factor),\n",
    "#         \"augmentation_type\": str(augmentation_type),\n",
    "        \"checkpoint_frequency\": str(checkpoint_frequency),\n",
    "#         \"augmentation_type\" : str(augmentation_type)\n",
    "    },\n",
    "    \"StoppingCondition\": {\n",
    "        \"MaxRuntimeInSeconds\": 360000\n",
    "    },\n",
    "#Training data should be inside a subdirectory called \"train\"\n",
    "#Validation data should be inside a subdirectory called \"validation\"\n",
    "#The algorithm currently only supports fullyreplicated model (where data is copied onto each machine)\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": 's3://{}/{}/train/'.format(bucket, s3_key),\n",
    "#                     \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                    \"S3DataDistributionType\": \"ShardedByS3Key\"\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"application/x-recordio\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"validation\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": 's3://{}/{}/validation/'.format(bucket, s3_key),\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"application/x-recordio\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "print('Training job name: {}'.format(job_name))\n",
    "print('\\nInput Data Location: {}'.format(training_params['InputDataConfig'][0]['DataSource']['S3DataSource']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.tuner import HyperparameterTuner, ContinuousParameter\n",
    "\n",
    "# # Configure HyperparameterTuner\n",
    "# my_tuner = HyperparameterTuner(estimator=my_estimator,  # previously-configured Estimator object\n",
    "#                                objective_metric_name='validation-accuracy',\n",
    "#                                hyperparameter_ranges={'learning-rate': ContinuousParameter(0.05, 0.06)},\n",
    "#                                metric_definitions=[{'Name': 'validation-accuracy', 'Regex': 'validation-accuracy=(\\d\\.\\d+)'}],\n",
    "#                                max_jobs=100,\n",
    "#                                max_parallel_jobs=10)\n",
    "\n",
    "# # Start hyperparameter tuning job\n",
    "# my_tuner.fit({'train': 's3://my_bucket/my_training_data', 'test': 's3://my_bucket_my_testing_data'})\n",
    "\n",
    "# # Deploy best model\n",
    "# my_predictor = my_tuner.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceInUse",
     "evalue": "An error occurred (ResourceInUse) when calling the CreateTrainingJob operation: Training job names must be unique within an AWS account and region, and a training job with this name already exists (arn:aws:sagemaker:us-east-1:649615449669:training-job/trashnet-imageclassification-2018-11-27-18-58-35)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceInUse\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-753ae2e0b380>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# create the Amazon SageMaker training job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msagemaker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboto3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sagemaker'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtraining_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# confirm that the training job has started\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    313\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceInUse\u001b[0m: An error occurred (ResourceInUse) when calling the CreateTrainingJob operation: Training job names must be unique within an AWS account and region, and a training job with this name already exists (arn:aws:sagemaker:us-east-1:649615449669:training-job/trashnet-imageclassification-2018-11-27-18-58-35)"
     ]
    }
   ],
   "source": [
    "# create the Amazon SageMaker training job\n",
    "sagemaker = boto3.client(service_name='sagemaker')\n",
    "sagemaker.create_training_job(**training_params)\n",
    "\n",
    "# confirm that the training job has started\n",
    "status = sagemaker.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "print('Training job current status: {}'.format(status))\n",
    "\n",
    "try:\n",
    "    # wait for the job to finish and report the ending status\n",
    "    sagemaker.get_waiter('training_job_completed_or_stopped').wait(TrainingJobName=job_name)\n",
    "    training_info = sagemaker.describe_training_job(TrainingJobName=job_name)\n",
    "    status = training_info['TrainingJobStatus']\n",
    "    print(\"Training job ended with status: \" + status)\n",
    "except:\n",
    "    print('Training failed to start')\n",
    "     # if exception is raised, that means it has failed\n",
    "    message = sagemaker.describe_training_job(TrainingJobName=job_name)['FailureReason']\n",
    "    print('Training failed with the following error: {}'.format(message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job current status: Completed\n",
      "Training job ended with status: Completed\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "sagemaker = boto3.client(service_name='sagemaker')\n",
    "job_name = 'trashnet-imageclassification-2018-11-27-18-58-35'\n",
    "\n",
    "# confirm that the training job has started\n",
    "status = sagemaker.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "print('Training job current status: {}'.format(status))\n",
    "\n",
    "try:\n",
    "    # wait for the job to finish and report the ending status\n",
    "    sagemaker.get_waiter('training_job_completed_or_stopped').wait(TrainingJobName=job_name)\n",
    "    training_info = sagemaker.describe_training_job(TrainingJobName=job_name)\n",
    "    status = training_info['TrainingJobStatus']\n",
    "    print(\"Training job ended with status: \" + status)\n",
    "except:\n",
    "    print('Training failed to start')\n",
    "     # if exception is raised, that means it has failed\n",
    "    message = sagemaker.describe_training_job(TrainingJobName=job_name)['FailureReason']\n",
    "    print('Training failed with the following error: {}'.format(message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Delete existing endpoint configuration + endpoint + update model\n",
    "# ## Create EndPoint Config\n",
    "# primary_container = \"\"\n",
    "# create_model_response = sagemaker.create_model(\n",
    "#     ModelName = model_name,\n",
    "#     ExecutionRoleArn = role,\n",
    "#     PrimaryContainer = primary_container)\n",
    "\n",
    "# response = sagemaker.create_endpoint_config(\n",
    "#     EndpointConfigName=endpoint_config_name,\n",
    "#     ProductionVariants=[\n",
    "#         {\n",
    "#             'VariantName': 'trashnet-imagenet-new',\n",
    "#             'ModelName': model_name,\n",
    "#             'InitialInstanceCount': 1,\n",
    "#             'InstanceType': 'ml.m4.xlarge'\n",
    "#         },\n",
    "#     ])\n",
    "\n",
    "# print (response)\n",
    "\n",
    "# ## Create Sagemaker Endpoint\n",
    "# response = sagemaker.create_endpoint(\n",
    "#     EndpointName=endpoint_name,\n",
    "#     EndpointConfigName=endpoint_config_name,\n",
    "# )\n",
    "\n",
    "# print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://farm2.static.flickr.com/1101/1030700323_7e3f92b758.jpg\n",
      "--2018-11-27 23:41:20--  http://farm2.static.flickr.com/1101/1030700323_7e3f92b758.jpg\n",
      "Resolving farm2.static.flickr.com (farm2.static.flickr.com)... 67.195.205.33\n",
      "Connecting to farm2.static.flickr.com (farm2.static.flickr.com)|67.195.205.33|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 143830 (140K) [image/jpeg]\n",
      "Saving to: ‘/tmp/test.jpg’\n",
      "\n",
      "/tmp/test.jpg       100%[===================>] 140.46K  --.-KB/s    in 0.07s   \n",
      "\n",
      "2018-11-27 23:41:20 (2.04 MB/s) - ‘/tmp/test.jpg’ saved [143830/143830]\n",
      "\n",
      "-------------\n",
      "\n",
      "Category input - bottle\n",
      "\n",
      "Results: [0.9887984395027161, 1.0231772762381297e-08, 5.2821011453652034e-11, 6.565922205936658e-08, 4.653782980312826e-06, 0.011194834485650063, 2.0016968846903183e-06, 2.6980877926817415e-13] \n",
      "\n",
      "Resulting label : bottle , probability : 0.9887984395027161 \n",
      "-------------\n",
      "http://www.toyhalloffame.org/sites/www.toyhalloffame.org/files/toys/square/cardboard-box-square.jpg\n",
      "--2018-11-27 23:41:21--  http://www.toyhalloffame.org/sites/www.toyhalloffame.org/files/toys/square/cardboard-box-square.jpg\n",
      "Resolving www.toyhalloffame.org (www.toyhalloffame.org)... 74.112.39.40, 74.43.95.148\n",
      "Connecting to www.toyhalloffame.org (www.toyhalloffame.org)|74.112.39.40|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 18117 (18K) [image/jpeg]\n",
      "Saving to: ‘/tmp/test.jpg’\n",
      "\n",
      "/tmp/test.jpg       100%[===================>]  17.69K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2018-11-27 23:41:23 (185 KB/s) - ‘/tmp/test.jpg’ saved [18117/18117]\n",
      "\n",
      "-------------\n",
      "\n",
      "Category input - cardboard\n",
      "\n",
      "Results: [0.05519959330558777, 0.008145814761519432, 0.9321285486221313, 1.5527578511864704e-07, 1.1898482910055463e-07, 0.004441282246261835, 7.019279291853309e-05, 1.4350380297400989e-05] \n",
      "\n",
      "Resulting label : coffee_cup , probability : 0.9321285486221313 \n",
      "-------------\n",
      "http://farm3.static.flickr.com/2146/2503344744_9d65322922.jpg\n",
      "--2018-11-27 23:41:24--  http://farm3.static.flickr.com/2146/2503344744_9d65322922.jpg\n",
      "Resolving farm3.static.flickr.com (farm3.static.flickr.com)... 67.195.205.33\n",
      "Connecting to farm3.static.flickr.com (farm3.static.flickr.com)|67.195.205.33|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 43809 (43K) [image/jpeg]\n",
      "Saving to: ‘/tmp/test.jpg’\n",
      "\n",
      "/tmp/test.jpg       100%[===================>]  42.78K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2018-11-27 23:41:24 (1.19 MB/s) - ‘/tmp/test.jpg’ saved [43809/43809]\n",
      "\n",
      "-------------\n",
      "\n",
      "Category input - coffee_cup\n",
      "\n",
      "Results: [0.052387744188308716, 7.034705049591139e-05, 0.9473221898078918, 1.324702134297695e-05, 2.179674083890859e-05, 0.00018465860921423882, 5.7324683666593046e-08, 6.478461322956264e-09] \n",
      "\n",
      "Resulting label : coffee_cup , probability : 0.9473221898078918 \n",
      "-------------\n",
      "http://farm3.static.flickr.com/2146/2503344744_9d65322922.jpg\n",
      "--2018-11-27 23:41:24--  http://farm3.static.flickr.com/2146/2503344744_9d65322922.jpg\n",
      "Resolving farm3.static.flickr.com (farm3.static.flickr.com)... 67.195.205.33\n",
      "Connecting to farm3.static.flickr.com (farm3.static.flickr.com)|67.195.205.33|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 43809 (43K) [image/jpeg]\n",
      "Saving to: ‘/tmp/test.jpg’\n",
      "\n",
      "/tmp/test.jpg       100%[===================>]  42.78K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2018-11-27 23:41:24 (1.17 MB/s) - ‘/tmp/test.jpg’ saved [43809/43809]\n",
      "\n",
      "-------------\n",
      "\n",
      "Category input - glass\n",
      "\n",
      "Results: [0.052387744188308716, 7.034705049591139e-05, 0.9473221898078918, 1.324702134297695e-05, 2.179674083890859e-05, 0.00018465860921423882, 5.7324683666593046e-08, 6.478461322956264e-09] \n",
      "\n",
      "Resulting label : coffee_cup , probability : 0.9473221898078918 \n",
      "-------------\n",
      "http://farm1.static.flickr.com/45/105983430_a0d3326d20.jpg\n",
      "--2018-11-27 23:41:25--  http://farm1.static.flickr.com/45/105983430_a0d3326d20.jpg\n",
      "Resolving farm1.static.flickr.com (farm1.static.flickr.com)... 67.195.205.33\n",
      "Connecting to farm1.static.flickr.com (farm1.static.flickr.com)|67.195.205.33|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 131406 (128K) [image/jpeg]\n",
      "Saving to: ‘/tmp/test.jpg’\n",
      "\n",
      "/tmp/test.jpg       100%[===================>] 128.33K  --.-KB/s    in 0.07s   \n",
      "\n",
      "2018-11-27 23:41:25 (1.91 MB/s) - ‘/tmp/test.jpg’ saved [131406/131406]\n",
      "\n",
      "-------------\n",
      "\n",
      "Category input - plastic\n",
      "\n",
      "Results: [0.4589751362800598, 0.08110678195953369, 0.3074491024017334, 0.03569759055972099, 0.04723288118839264, 0.0021267784759402275, 0.06738130003213882, 3.0405421057366766e-05] \n",
      "\n",
      "Resulting label : bottle , probability : 0.4589751362800598 \n",
      "-------------\n",
      "http://farm3.static.flickr.com/2089/2352391295_422eeec9bc.jpg\n",
      "--2018-11-27 23:41:26--  http://farm3.static.flickr.com/2089/2352391295_422eeec9bc.jpg\n",
      "Resolving farm3.static.flickr.com (farm3.static.flickr.com)... 67.195.205.33\n",
      "Connecting to farm3.static.flickr.com (farm3.static.flickr.com)|67.195.205.33|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 111784 (109K) [image/jpeg]\n",
      "Saving to: ‘/tmp/test.jpg’\n",
      "\n",
      "/tmp/test.jpg       100%[===================>] 109.16K  --.-KB/s    in 0.07s   \n",
      "\n",
      "2018-11-27 23:41:26 (1.62 MB/s) - ‘/tmp/test.jpg’ saved [111784/111784]\n",
      "\n",
      "-------------\n",
      "\n",
      "Category input - plastic_bag\n",
      "\n",
      "Results: [0.998138427734375, 0.0018612970598042011, 2.444133428980422e-07, 1.0961968312239723e-11, 1.627533552372995e-09, 1.201628813812805e-11, 5.229767729986179e-09, 2.2919222075756807e-09] \n",
      "\n",
      "Resulting label : bottle , probability : 0.998138427734375 \n",
      "-------------\n",
      "http://farm4.static.flickr.com/3446/3393921436_a7b6be433e.jpg\n",
      "--2018-11-27 23:41:27--  http://farm4.static.flickr.com/3446/3393921436_a7b6be433e.jpg\n",
      "Resolving farm4.static.flickr.com (farm4.static.flickr.com)... 67.195.205.33\n",
      "Connecting to farm4.static.flickr.com (farm4.static.flickr.com)|67.195.205.33|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 88496 (86K) [image/jpeg]\n",
      "Saving to: ‘/tmp/test.jpg’\n",
      "\n",
      "/tmp/test.jpg       100%[===================>]  86.42K  --.-KB/s    in 0.05s   \n",
      "\n",
      "2018-11-27 23:41:27 (1.69 MB/s) - ‘/tmp/test.jpg’ saved [88496/88496]\n",
      "\n",
      "-------------\n",
      "\n",
      "Category input - soda_can\n",
      "\n",
      "Results: [2.557629441568565e-09, 5.792026303019782e-10, 0.0021483656018972397, 3.556873406918015e-10, 2.4696152241265867e-12, 8.218170068075015e-13, 0.9978512525558472, 4.0398768419436237e-07] \n",
      "\n",
      "Resulting label : soda_can , probability : 0.9978512525558472 \n",
      "-------------\n",
      "https://s3.amazonaws.com/reinvent2018-recycle-arm-us-east-1/samples/trash/trash1.jpg\n",
      "--2018-11-27 23:41:28--  https://s3.amazonaws.com/reinvent2018-recycle-arm-us-east-1/samples/trash/trash1.jpg\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.237.237\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.237.237|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 16718 (16K) [image/jpeg]\n",
      "Saving to: ‘/tmp/test.jpg’\n",
      "\n",
      "/tmp/test.jpg       100%[===================>]  16.33K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2018-11-27 23:41:28 (16.2 MB/s) - ‘/tmp/test.jpg’ saved [16718/16718]\n",
      "\n",
      "-------------\n",
      "\n",
      "Category input - trash\n",
      "\n",
      "Results: [2.855144731750414e-10, 6.748874896433943e-12, 3.849897733942953e-09, 0.9808734059333801, 0.018787696957588196, 6.116797172939226e-12, 3.751989604422468e-12, 0.00033891270868480206] \n",
      "\n",
      "Resulting label : glass , probability : 0.9808734059333801 \n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "import boto3\n",
    "runtime = boto3.Session().client(service_name='runtime.sagemaker') \n",
    "\n",
    "object_categories = ['bottle', 'cardboard','coffee_cup','glass', 'plastic', 'plastic_bag', 'soda_can', 'trash']\n",
    "endpoint_name = 'trashnet-imagenet-new'\n",
    "\n",
    "image_list = {\"bottle\" : \"http://farm2.static.flickr.com/1101/1030700323_7e3f92b758.jpg\",\n",
    "              \"cardboard\": \"http://www.toyhalloffame.org/sites/www.toyhalloffame.org/files/toys/square/cardboard-box-square.jpg\",\n",
    "              \"coffee_cup\": \"http://farm3.static.flickr.com/2146/2503344744_9d65322922.jpg\",\n",
    "              \"glass\": \"http://farm3.static.flickr.com/2146/2503344744_9d65322922.jpg\",\n",
    "              \"plastic\": \"http://farm1.static.flickr.com/45/105983430_a0d3326d20.jpg\",\n",
    "              \"plastic_bag\": \"http://farm3.static.flickr.com/2089/2352391295_422eeec9bc.jpg\",\n",
    "              \"soda_can\" : \"http://farm4.static.flickr.com/3446/3393921436_a7b6be433e.jpg\",\n",
    "             \"trash\" : \"https://s3.amazonaws.com/reinvent2018-recycle-arm-us-east-1/samples/trash/trash1.jpg\"}\n",
    "\n",
    "for image_category, image_category_file_path in image_list.items():\n",
    "    print(image_category_file_path)\n",
    "    !wget -O /tmp/test.jpg $image_category_file_path\n",
    "    file_name = '/tmp/test.jpg'\n",
    "    \n",
    "    with open(file_name, 'rb') as f:\n",
    "        payload = f.read()\n",
    "        payload = bytearray(payload)\n",
    "    response = runtime.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                       ContentType='application/x-image', \n",
    "                                       Body=payload)\n",
    "    result = response['Body'].read()\n",
    "    # result will be in json format and convert it to ndarray\n",
    "    result = json.loads(result)\n",
    "    print (\"-------------\\n\")\n",
    "    print (\"Category input - {}\\n\".format(image_category))\n",
    "    print (\"Results: {} \\n\".format(result))\n",
    "    index = np.argmax(result)\n",
    "    print(\"Resulting label : {} , probability : {} \".format(object_categories[index],str(result[index])))\n",
    "    print (\"-------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
